{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "43JwPOeZnWB4"
      },
      "outputs": [],
      "source": [
        "# Import all the libraries and dependencies\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zhmNMLsVwZ-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f185119-2111-4da6-9c52-adc890032385"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the data and preprocessing it\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/C.V/data/Train'\n",
        "test_dir = '/content/drive/MyDrive/C.V/data/Test'\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xJZFh5T0zLGW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, # path for training set\n",
        "                                                    target_size=(150, 150), # setting input size to ensure uniformity\n",
        "                                                    batch_size=32, # creating batches of dataset\n",
        "                                                    class_mode='categorical') #categorical as we have 3 categories\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(150, 150),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8fKQVfl0dyV",
        "outputId": "bcd956bd-46d9-4e48-dc4b-7bafbe591170"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 385 images belonging to 3 classes.\n",
            "Found 138 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the VGG16 model from tensorflow and using the same weights applied during imagenet competition\n",
        "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "# this will exclude the top layers from training phase as our dataset only has 3 categories\n",
        "vgg16.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwFzOPiC066P",
        "outputId": "ee011254-1316-4568-f626-e3787d0cf7dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model creation\n",
        "model = Sequential()\n",
        "model.add(vgg16) # adding VG16 model architecture\n",
        "model.add(Flatten()) # to flatten and create a single dimensional array\n",
        "model.add(Dense(128, activation=\"relu\")) \n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(3, activation='softmax')) \n",
        "#adding the output layer with softmax function as this is a multi label classification problem.\n",
        "vgg16.trainable = False\n",
        "# this will exclude the initial layers from training phase as there are already been trained."
      ],
      "metadata": {
        "id": "iBysLWTZ1Pq6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "model.fit_generator(train_generator,epochs=5) # fitting the model on the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rrwBfVj1_bv",
        "outputId": "776822f7-d8a0-4d74-895a-0feb50347e01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-fb2c6d3c7ab5>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator,epochs=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 108ms/step - loss: 0.8122 - accuracy: 0.6701\n",
            "Epoch 2/5\n",
            "13/13 [==============================] - 2s 112ms/step - loss: 0.3556 - accuracy: 0.8753\n",
            "Epoch 3/5\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.2109 - accuracy: 0.9221\n",
            "Epoch 4/5\n",
            "13/13 [==============================] - 1s 120ms/step - loss: 0.0893 - accuracy: 0.9740\n",
            "Epoch 5/5\n",
            "13/13 [==============================] - 2s 112ms/step - loss: 0.0392 - accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec00677e20>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(\"The testing datas loss percentage calculated is:\",test_loss)\n",
        "print(\"The accuracy of the while testing the model is: \",test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btUekOaE2U3P",
        "outputId": "07b59c04-d988-4849-9ee4-002f4525eaff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 84ms/step - loss: 0.4659 - accuracy: 0.8406\n",
            "The testing datas loss percentage calculated is: 0.46591782569885254\n",
            "The accuracy of the while testing the model is:  0.8405796885490417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the model\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "img = load_img('/content/drive/MyDrive/C.V/data/b1.jpg',target_size=(150, 150) )\n",
        "x = np.array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds=model.predict(x)\n",
        "# create a list containing the class labels\n",
        "class_labels = ['Apple','Banana','Orange']\n",
        "\n",
        "# find the index of the class with maximum score\n",
        "pred = np.argmax(preds, axis=-1)\n",
        "\n",
        "# print the label of the class with maximum score\n",
        "print(class_labels[pred[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgkfMdD05QjW",
        "outputId": "a9a9adca-1b14-4142-bbbc-1fb965d8dabf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Banana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SE7cPMjvFwdW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}